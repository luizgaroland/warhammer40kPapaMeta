# Application Settings
SERVICE_NAME=wahapedia-scraper
LOG_LEVEL=info
WORKERS=4
DEBUG=false

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
REDIS_MAX_CONNECTIONS=50

# PostgreSQL Configuration
DATABASE_URL=postgresql://postgres:password@postgres:5432/wahapedia_scraper
POSTGRES_PASSWORD=secure_password_here
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=0

# Celery Configuration
CELERY_BROKER_URL=redis://redis:6379/1
CELERY_RESULT_BACKEND=redis://redis:6379/2
CELERY_TASK_SERIALIZER=json
CELERY_RESULT_SERIALIZER=json
CELERY_ACCEPT_CONTENT=json
CELERY_TIMEZONE=UTC
CELERY_ENABLE_UTC=true

# Scraping Configuration
SCRAPING_DELAY=1.0  # Seconds between requests
REQUEST_TIMEOUT=30  # Seconds
MAX_RETRIES=3
RETRY_DELAY=5  # Seconds
USER_AGENT=WH40K-Meta-Analysis-Bot/1.0 (https://github.com/yourusername/project)
MAX_CONCURRENT_REQUESTS=5
RESPECT_ROBOTS_TXT=true

# Wahapedia Specific
WAHAPEDIA_BASE_URL=https://wahapedia.ru
WAHAPEDIA_40K_PATH=/wh40k10ed
WAHAPEDIA_RATE_LIMIT=1  # Requests per second

# Feature Flags
ENABLE_INCREMENTAL_SCRAPING=true
ENABLE_VERSION_DETECTION=true
ENABLE_CHANGE_DETECTION=true
ENABLE_CACHE=true
ENABLE_METRICS=true

# Cache Settings
CACHE_TTL=3600  # Seconds
CACHE_MAX_SIZE=1000  # Number of items

# Monitoring
SENTRY_DSN=
PROMETHEUS_PORT=9000
ENABLE_HEALTH_CHECK=true
HEALTH_CHECK_INTERVAL=30

# External Services
GW_TRIGGER_SERVICE_URL=http://gw-trigger:8001
LARAVEL_API_URL=http://laravel-backend:8080
REDIS_CHANNEL_PREFIX=wahapedia:

# Security
API_KEY=your_api_key_here
SECRET_KEY=your_secret_key_here
ALLOWED_HOSTS=localhost,127.0.0.1

# Scheduling (Cron expressions)
FULL_SCRAPE_SCHEDULE=0 2 * * 0  # Every Sunday at 2 AM
INCREMENTAL_SCRAPE_SCHEDULE=0 */6 * * *  # Every 6 hours
HEALTH_CHECK_SCHEDULE=*/5 * * * *  # Every 5 minutes

# Performance Tuning
CONNECTION_POOL_SIZE=10
BATCH_SIZE=100
CHUNK_SIZE=1000
MEMORY_LIMIT_MB=512

# Development Settings (override in production)
DEV_MODE=false
MOCK_SCRAPING=false
SAVE_HTML_SNAPSHOTS=false
VERBOSE_LOGGING=false
